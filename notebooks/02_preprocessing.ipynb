{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b91fa456",
   "metadata": {},
   "source": [
    "# Setup & imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ddeb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Activation du rechargement automatique (utile en dev local)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f22f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path().resolve().parent\n",
    "inputs_dir = base_dir / \"data\"\n",
    "notebook_dir = base_dir / \"notebooks\"\n",
    "src_dir = base_dir / \"src\"\n",
    "\n",
    "for dir in [base_dir, inputs_dir, notebook_dir, src_dir]:\n",
    "    dir.mkdir(parents=True, exist_ok=True)\n",
    "    sys.path.insert(0, str(dir.resolve()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7e7f40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3365, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3610, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3670, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Temp\\ipykernel_6700\\4228886005.py\", line 2, in <module>\n",
      "    from preprocessing.text_cleaner import clean_pipeline\n",
      "  File \"C:\\Users\\beedi.goua_square-ma\\Desktop\\Gheb\\projet perso\\ReviewGuardian\\src\\preprocessing\\text_cleaner.py\", line 4, in <module>\n",
      "    import spacy\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py\", line 6, in <module>\n",
      "    from .errors import setup_default_warnings\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\errors.py\", line 3, in <module>\n",
      "    from .compat import Literal\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\compat.py\", line 4, in <module>\n",
      "    from thinc.util import copy_array\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\__init__.py\", line 5, in <module>\n",
      "    from .config import registry\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\config.py\", line 5, in <module>\n",
      "    from .types import Decorator\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\types.py\", line 27, in <module>\n",
      "    from .compat import cupy, has_cupy\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\thinc\\compat.py\", line 35, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\beedi.goua_square-ma\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nltk\\metrics\\association.py:26: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 2.3.1)\n",
      "  from scipy.stats import fisher_exact\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Modules personnalisés (chemins selon ton projet)\n",
    "from preprocessing.text_cleaner import clean_pipeline\n",
    "from preprocessing.labeling import (\n",
    "    generate_toxic_labels,\n",
    "    analyze_label_distribution,\n",
    "    preview_labeled_samples,\n",
    "    add_toxic_source,\n",
    "    create_balanced_subset\n",
    ")\n",
    "from preprocessing.feature_engineering import enrich_text_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd99f4",
   "metadata": {},
   "source": [
    "# Chargement des données issues de la phase 1 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0c278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données chargées : 15000 lignes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>id_review</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>lexical_density</th>\n",
       "      <th>potential_toxic</th>\n",
       "      <th>flag_badwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Stuning even for the non-gamer</td>\n",
       "      <td>This sound track was beautiful! It paints the ...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R_000000</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>394</td>\n",
       "      <td>5.253333</td>\n",
       "      <td>57</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.</td>\n",
       "      <td>I'm reading a lot of reviews saying that this ...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>R_000001</td>\n",
       "      <td>5</td>\n",
       "      <td>91</td>\n",
       "      <td>470</td>\n",
       "      <td>5.164835</td>\n",
       "      <td>69</td>\n",
       "      <td>0.758242</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                  title  \\\n",
       "0          1         Stuning even for the non-gamer   \n",
       "1          1  The best soundtrack ever to anything.   \n",
       "\n",
       "                                                text  source id_review  \\\n",
       "0  This sound track was beautiful! It paints the ...  amazon  R_000000   \n",
       "1  I'm reading a lot of reviews saying that this ...  amazon  R_000001   \n",
       "\n",
       "   n_sentences  n_words  n_chars  avg_word_len  n_unique_words  \\\n",
       "0            3       75      394      5.253333              57   \n",
       "1            5       91      470      5.164835              69   \n",
       "\n",
       "   lexical_density  potential_toxic  flag_badwords  \n",
       "0         0.760000             True           True  \n",
       "1         0.758242            False          False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Définition des chemins\n",
    "base_dir = Path().resolve().parent\n",
    "input_path = base_dir / \"data\" / \"processed\" / \"merged_reviews_eda.csv\"\n",
    "\n",
    "# Chargement\n",
    "df = pd.read_csv(input_path)\n",
    "print(f\"Données chargées : {df.shape[0]} lignes\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ea269",
   "metadata": {},
   "source": [
    "#### Remarque : \n",
    "Ces données sont le résultat de l’analyse exploratoire de la phase 1. Elles contiennent des colonnes comme n_words, potential_toxic, flag_badwords, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7ea7c",
   "metadata": {},
   "source": [
    "## Netoyage textuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d99b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données nettoyées : 14957 lignes restantes après filtrage\n"
     ]
    }
   ],
   "source": [
    "df_clean = clean_pipeline(df, text_col=\"text\", min_words=5, max_words=500)\n",
    "print(f\"Données nettoyées : {df_clean.shape[0]} lignes restantes après filtrage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344aa545",
   "metadata": {},
   "source": [
    "#### Commentaires :\n",
    "\n",
    "Texte nettoyé disponible dans text_clean\n",
    "\n",
    "Filtrage automatique des textes trop courts ou trop longs\n",
    "\n",
    "Punctuation, HTML, emojis, emails, chiffres → supprimés\n",
    "\n",
    "Lemmatisation avec SpaCy\n",
    "\n",
    "Stopwords supprimés avec NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8eb127",
   "metadata": {},
   "source": [
    "# Génération de l’étiquette label_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a0feb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.labeling:Étiquetage terminé : 3648 textes toxiques sur 14957\n"
     ]
    }
   ],
   "source": [
    "df_labeled = generate_toxic_labels(df_clean, toxic_col=\"potential_toxic\", badword_col=\"flag_badwords\")\n",
    "\n",
    "# Ajout de colonne explicative (source de toxicité)\n",
    "df_labeled = add_toxic_source(df_labeled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e546d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution des étiquettes :\n",
      " - Classe 0 : 11309 avis (75.61%)\n",
      " - Classe 1 : 3648 avis (24.39%)\n",
      "\n",
      "Vérifie s’il y a un déséquilibre significatif avant la modélisation (phase 2.4).\n",
      "\n",
      "Exemples de textes étiquetés (5 par classe) :\n",
      "\n",
      "--- Classe 0 ---\n",
      "→ Great movie and so glad to see this released to (Blu-Ray). Keep anything of John Wayne's great movies released on (blu-ray) coming as soon as they Ava...\n",
      "→ This book has it's place--and that place is in an American Literature course at a university. It was entirely too technical to be enjoyable. I was ass...\n",
      "→ Orwell's tale of a society where not only behaviour, but also thought is controlled, seems to grow ever more relevant as the years pass and new techno...\n",
      "→ This was the first novel I've read by Shari MacDonald. It was great. She ranks right up there with Lori Wick and Lori Copeland. This is a must read....\n",
      "→ but I had to make the time to finish the book to make sure that I wasn't missing anything. At times I felt there was something else that needed to be ...\n",
      "\n",
      "--- Classe 1 ---\n",
      "→ This movie could be used in film classes in a \"How Not to Script a B-Movie\" course. There are inherent constrictions in a B-movie: Budgets are tight, ...\n",
      "→ I cant believe some people actually like this. Yet still call themselves Batman fans. Even going as far as to say it's better than BTAS. Which it's no...\n",
      "→ I rented this movie today thinking it might be a good football movie, since I'm a big football fan. Boy, was I wrong. This movie is way too religious ...\n",
      "→ Absolutely horrific film. Ameteurish and it isn't funny at all. Lead character played by Mehmet Ali Erbil is very annoying. Edits by E.T and star wars...\n",
      "→ Wow. That's about as much as I can say right now. Who writes this stuff? Who produces this stuff? What self-respecting actor would agree to 'act' in t...\n"
     ]
    }
   ],
   "source": [
    "# Distribution\n",
    "analyze_label_distribution(df_labeled)\n",
    "preview_labeled_samples(df_labeled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2908714",
   "metadata": {},
   "source": [
    "#### Commentaires :\n",
    "\n",
    "label_toxic = 1 si le texte est potentiellement toxique ou contient des injures\n",
    "\n",
    "Distribution des classes affichée\n",
    "\n",
    "Des exemples de chaque classe sont visualisés\n",
    "\n",
    "toxic_source donne la source du flag (injure, toxicité, ou les deux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8d020",
   "metadata": {},
   "source": [
    "# Enrichissement linguistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc61cec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flesch_score</th>\n",
       "      <th>fk_grade</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment_subjectivity</th>\n",
       "      <th>capital_ratio</th>\n",
       "      <th>nb_exclamations</th>\n",
       "      <th>nb_questions</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_email</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>has_repeated_chars</th>\n",
       "      <th>has_emoji</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.220000</td>\n",
       "      <td>18.005000</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.877500</td>\n",
       "      <td>22.550833</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.522449</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.997105</td>\n",
       "      <td>32.836842</td>\n",
       "      <td>0.196719</td>\n",
       "      <td>0.572899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flesch_score   fk_grade  sentiment_polarity  sentiment_subjectivity  \\\n",
       "0     37.220000  18.005000           -0.075000                0.510000   \n",
       "1     18.877500  22.550833            0.150000                0.522449   \n",
       "2     -4.997105  32.836842            0.196719                0.572899   \n",
       "\n",
       "   capital_ratio  nb_exclamations  nb_questions  has_url  has_email  \\\n",
       "0       0.000000                0             0    False      False   \n",
       "1       0.007194                0             0    False      False   \n",
       "2       0.000000                0             0    False      False   \n",
       "\n",
       "   has_phone  has_repeated_chars  has_emoji  \n",
       "0      False               False      False  \n",
       "1      False               False      False  \n",
       "2      False               False      False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enriched = enrich_text_features(df_labeled, text_col=\"text_clean\")\n",
    "# Aperçu enrichissement\n",
    "df_enriched[[\n",
    "    \"flesch_score\", \"fk_grade\",\n",
    "    \"sentiment_polarity\", \"sentiment_subjectivity\",\n",
    "    \"capital_ratio\", \"nb_exclamations\", \"nb_questions\",\n",
    "    \"has_url\", \"has_email\", \"has_phone\",\n",
    "    \"has_repeated_chars\", \"has_emoji\"\n",
    "]].head(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d0bb4",
   "metadata": {},
   "source": [
    "# Rééquilibrage des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2896c709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:preprocessing.labeling:Jeu équilibré créé : 7296 lignes (classe 0: 3648, classe 1: 3648)\n"
     ]
    }
   ],
   "source": [
    "df_balanced = create_balanced_subset(df_enriched, label_col=\"label_toxic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = base_dir / \"data\" / \"processed\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_clean.to_csv(output_dir / \"clean_reviews.csv\", index=False)\n",
    "df_enriched.to_csv(output_dir / \"enriched_reviews.csv\", index=False)\n",
    "df_balanced.to_csv(output_dir / \"balanced_reviews.csv\", index=False)\n",
    "\n",
    "print(\"Jeux sauvegardés : clean / enriched / balanced\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
