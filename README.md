
# SafeText ModÃ©ration â€” Pipeline local de dÃ©tection de toxicitÃ©

Projet de modÃ©ration de texte automatisÃ©e (Trustpilot, Amazon, IMDB) avec extraction, enrichissement, visualisation et export local. Tout est conÃ§u pour rester **RGPD-friendly**, **reproductible**, et **sans API externe**.

---

## Objectifs du projet

- Collecter des avis (rÃ©els + synthÃ©tiques)
- Analyser et enrichir automatiquement les textes
- DÃ©tecter les contenus **toxiques**, **injurieux** ou **suspects**
- Explorer visuellement les corrÃ©lations et comportements anormaux
- Produire un **CSV enrichi** exploitable pour entraÃ®nement ou monitoring

---

## Structure du projet

```bash
project/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # DonnÃ©es brutes (amazon, imdb, scraping)
â”‚   â”œâ”€â”€ processed/         # DonnÃ©es nettoyÃ©es + enrichies
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_reviews.ipynb     # Analyse exploratoire complÃ¨te
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ synthetic_generator.py      # GÃ©nÃ©rateur d'avis synthÃ©tiques
â”‚   â”‚   â””â”€â”€ scrapers/
â”‚   â”‚       â””â”€â”€ review_scraper.py       # Scraper Trustpilot (Scrapy)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore



## Installation

```bash
git clone https://github.com/ton_profil/safetext-moderation.git
cd safetext-moderation
pip install -r requirements.txt
```

---

## DÃ©marrage rapide

### 1. GÃ©nÃ©rer ou scraper des donnÃ©es

* **Scraper Trustpilot** :

```python
from src.data.scrapers.review_scraper import scrape_reviews
scrape_reviews(["https://fr.trustpilot.com/review/example.com"], "data/raw/trustpilot_reviews.csv")
```

* **GÃ©nÃ©rer des avis synthÃ©tiques** :

```python
from src.data.synthetic_generator import SyntheticReviewGenerator

gen = SyntheticReviewGenerator(seed=42)
df = gen.generate_reviews(n_positive=200, n_negative=200, n_neutral=100, save_path="data/raw/synthetic.csv")
```

### 2. Lancer lâ€™analyse exploratoire (`notebooks/01_EDA_reviews.ipynb`)

Contenu du notebook :

* Fusion des jeux de donnÃ©es
* Extraction de features (n\_words, n\_sentences, lexical\_densityâ€¦)
* WordCloud, top mots, bigrams, TF-IDF
* Analyse de sentiment (IMDB)
* DÃ©tection de toxicitÃ© (`potential_toxic`) et injures (`flag_badwords`)
* CorrÃ©lations, heatmaps, outliers, scatterplots
* Enregistrement du CSV enrichi

---

## ğŸ” Exemple de dÃ©tection (regex + score TF-IDF)

| Champ             | Exemple                                                     |
| ----------------- | ----------------------------------------------------------- |
| `potential_toxic` | `True` si mots comme `terrible`, `stupid`, `awful`, etc.    |
| `flag_badwords`   | `True` si mots injurieux comme `fuck`, `bitch`, `retard`... |
| `lexical_density` | Ratio mots uniques / total â€” dÃ©tecte rÃ©pÃ©titions ou spam    |

---

## ğŸ§  Prochaines idÃ©es

* Ajouter un **modÃ¨le ML local** (ex : LogisticRegression) pour prÃ©dire la toxicitÃ©
* Convertir en API FastAPI ou interface Streamlit
* IntÃ©grer des embeddings + RAG pour modÃ©ration contextuelle
* Exploitation avec SHAP/LIME pour interprÃ©ter les dÃ©cisions

---

## ğŸ‘¨â€ğŸ’» Auteur

Projet rÃ©alisÃ© dans un cadre personnel de montÃ©e en compÃ©tences en **modÃ©ration NLP**, **scraping Ã©thique** et **analyse textuelle**.
Par \[Ton Nom / Ton GitHub].

---

## ğŸ“„ Licence

Ce projet est libre et open-source sous licence MIT.

```

---

Souhaites-tu aussi que je tâ€™Ã©crive le `requirements.txt` pour ce projet ? Ou une version avec badge GitHub, liens, ou version anglaise ?
```
